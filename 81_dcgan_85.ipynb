{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import (\n",
    "#     multiply,\n",
    "#     concatenate,\n",
    "# )\n",
    "# from tensorflow.keras.layers import MaxPooling2D\n",
    "# from tensorflow.keras.layers import GaussianNoise, GaussianDropout\n",
    "# from tensorflow.keras.layers import Lambda\n",
    "\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import cv2\n",
    "\n",
    "# import PIL\n",
    "\n",
    "# from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# https://github.com/eriklindernoren/Keras-GAN/blob/master/dcgan/dcgan.py\n",
    "# from keras.datasets import mnist\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    Reshape,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    "    Activation,\n",
    "    ZeroPadding2D,\n",
    "    LeakyReLU,\n",
    "    UpSampling2D,\n",
    "    Conv2D,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import pathlib\n",
    "\n",
    "import time\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  1.15.2\n",
      "Keras version:  2.2.4-tf\n",
      "Is eager execution enabled:  True\n",
      "Is there a GPU available:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow version: \", tf.VERSION)  # 1.15.2\n",
    "print(\"Keras version: \", tf.keras.__version__)  # 2.2.4-tf\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "print(\"Is eager execution enabled: \", tf.executing_eagerly())\n",
    "print(\"Is there a GPU available: \", tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_full_tfrecord = \"/data/fp85.tfrecord\"\n",
    "dir_save = \"dcgan_85\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@moritzkrger/speeding-up-keras-with-tfrecord-datasets-5464f9836c36\n",
    "\n",
    "BUFFER_SIZE = 1024\n",
    "\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    # Create a description of the features.\n",
    "    feature_description = {\n",
    "        \"floorplan\": tf.io.FixedLenFeature(\n",
    "            [28, 28, 6], tf.float32, default_value=tf.zeros([28, 28, 6], tf.float32)\n",
    "        ),\n",
    "        \"plan_id\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "        \"norm_year\": tf.io.FixedLenFeature([], tf.float32, default_value=-1.0),\n",
    "        \"sido\": tf.io.FixedLenFeature([], tf.int64, default_value=-1),\n",
    "        \"norm_area\": tf.io.FixedLenFeature([], tf.float32, default_value=0.0),\n",
    "        \"num_rooms\": tf.io.FixedLenFeature([], tf.int64, default_value=-1),\n",
    "        \"num_baths\": tf.io.FixedLenFeature([], tf.int64, default_value=-1),\n",
    "        \"brands\": tf.io.FixedLenFeature(\n",
    "            [12], tf.int64, default_value=tf.zeros([12], tf.int64)\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    # Parse the input tf.Example proto using the dictionary above.\n",
    "    parsed_example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "    return (parsed_example[\"floorplan\"],)\n",
    "    # return (parsed_example[\"floorplan\"], parsed_example[\"brands\"])\n",
    "\n",
    "\n",
    "def _onehot_fp(fp, *rest):\n",
    "    \"\"\"\n",
    "    Replace unit layer with outdoor layer and restrict function space layers indoor\n",
    "    \"\"\"\n",
    "    fp_func = fp[:, :, 1:6] * tf.reshape(fp[:, :, 0], (28, 28, 1))\n",
    "    fp_out = tf.reshape(1 - fp[:, :, 0], (28, 28, 1))\n",
    "    return (tf.concat([fp_out, fp_func], axis=2), *rest)\n",
    "\n",
    "\n",
    "def _rescale_fp(fp, *rest):\n",
    "    \"\"\"\n",
    "    Rescale from [0, 1] to [-1, 1]\n",
    "    \"\"\"\n",
    "    return (fp * 2 - 1, *rest)\n",
    "\n",
    "\n",
    "def _rescale_fp_brand(fp, brand, *rest):\n",
    "    \"\"\"\n",
    "    Rescale from [0, 1] to [-1, 1]\n",
    "    \"\"\"\n",
    "    return (fp * 2 - 1, brand * 2 - 1, *rest)\n",
    "\n",
    "def _visualize_fp_onehot(fps):\n",
    "    # adjusted for different luminance\n",
    "    channel_to_rgba = np.array(\n",
    "        [\n",
    "            [0.0, 0.0, 0.0, 0.0],  # ignore outdoor mask\n",
    "            [0.0, 0.33, 0.0, 0.0],  # entrance to green L30\n",
    "            [1.0, 0.25, 0.0, 0.0],  # LDK to red L57\n",
    "            [0.0, 0.26, 1.0, 0.0],  # bedroom to blue L40\n",
    "            [0.83, 0.87, 0.0, 0.0],  # balcony to yellow L85\n",
    "            [0.0, 0.81, 0.76, 0.0],\n",
    "        ]\n",
    "    )  # bathroom to cyan L75\n",
    "\n",
    "    # make colors subtractive\n",
    "    channel_to_rgba[1:6, 0:3] -= 1\n",
    "\n",
    "    # put it on white\n",
    "    fps_rgba = np.clip(\n",
    "        np.array([1.0, 1.0, 1.0, 1.0]) + (np.array(fps) @ channel_to_rgba), 0, 1\n",
    "    )\n",
    "    return fps_rgba\n",
    "\n",
    "\n",
    "def create_dataset(filepath, batch_size=8):\n",
    "\n",
    "    # This works with arrays as well\n",
    "    dataset = tf.data.TFRecordDataset(filepath, compression_type=\"GZIP\")\n",
    "\n",
    "    # Maps the parser on every filepath in the array. You can set the number of parallel loaders here\n",
    "    dataset = dataset.map(_parse_function, num_parallel_calls=4)\n",
    "\n",
    "    # make the floorplan one-hot-ish\n",
    "    dataset = dataset.map(_onehot_fp, num_parallel_calls=4)\n",
    "\n",
    "    # rescale to [-1, 1]\n",
    "    dataset = dataset.map(_rescale_fp, num_parallel_calls=4)\n",
    "\n",
    "    # This dataset will go on forever\n",
    "    dataset = dataset.repeat()\n",
    "\n",
    "    # Set the number of datapoints you want to load and shuffle\n",
    "    dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "\n",
    "    # Set the batchsize\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = create_dataset(path_full_tfrecord)\n",
    "# dataset_iter = tf.compat.v1.data.make_one_shot_iterator(dataset)\n",
    "# plt.imshow(_visualize_fp_onehot(next(dataset_iter)[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN_fp:\n",
    "    def __init__(self, dir_save=\"dcgan\"):\n",
    "        # Input shape\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 6\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "        self.dir_save = dir_save\n",
    "\n",
    "        pathlib.Path(self.dir_save).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(\n",
    "            loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    "        )\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid, name=\"combined\")\n",
    "        self.combined.summary()\n",
    "        self.combined.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "        model = Sequential(name=\"generator\")\n",
    "\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        model = Sequential(name=\"discriminator\")\n",
    "\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"\n",
    "            )\n",
    "        )\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(\n",
    "        self, path_tfrecord, epochs=201, initial_epoch=0, batch_size=128, save_interval=1,\n",
    "    ):\n",
    "        if initial_epoch:\n",
    "            self.load_model(initial_epoch - 1)\n",
    "\n",
    "        n_examples = sum(\n",
    "            1 for _ in tf.data.TFRecordDataset(path_tfrecord, compression_type=\"GZIP\")\n",
    "        )\n",
    "        batches_per_epoch = math.ceil(n_examples / batch_size)\n",
    "\n",
    "        # create a floorplan data iterator with size of half batch\n",
    "        train_dataset = create_dataset(path_tfrecord, batch_size=batch_size // 2)\n",
    "        dataset_iter = tf.compat.v1.data.make_one_shot_iterator(train_dataset)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid_full = np.ones((batch_size, 1))\n",
    "        valid_double = np.ones((batch_size*2, 1))\n",
    "        \n",
    "        valid_half = np.ones((batch_size // 2, 1))\n",
    "        fake_half = np.zeros((batch_size // 2, 1))\n",
    "\n",
    "        # zero knowlegde guess for starting loss\n",
    "        d_loss_fake = [-math.log(0.5), 0.5]\n",
    "        g_loss = -math.log(0.5)\n",
    "\n",
    "        # start time\n",
    "\n",
    "        t0 = time.time()\n",
    "        t1 = t0\n",
    "\n",
    "        for epoch in range(initial_epoch, initial_epoch + epochs):\n",
    "            for _ in range(batches_per_epoch):\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "\n",
    "                # Load a half batch of floorplan images\n",
    "                imgs = next(dataset_iter)[0].numpy()\n",
    "\n",
    "                # Sample noise and generate a half batch of new images\n",
    "                noise = np.random.normal(0, 1, (batch_size // 2, self.latent_dim))\n",
    "                gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                # Train the discriminator (real classified as ones and generated as zeros)\n",
    "                d_loss_real = self.discriminator.train_on_batch(imgs, valid_half)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake_half)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "\n",
    "                # Sample noise and generate a batch of new images\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "                # Train the generator (wants discriminator to mistake images as real)\n",
    "                g_loss = self.combined.train_on_batch(noise, valid_full)\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0 or epoch == initial_epoch + epochs - 1:\n",
    "\n",
    "                # Plot the progress\n",
    "                print(\n",
    "                    \"%d [D loss: %f, acc.: %.1f%%] [G loss: %f]\"\n",
    "                    % (epoch, d_loss[0], 100 * d_loss[1], g_loss),\n",
    "                    end=\" \",\n",
    "                )\n",
    "\n",
    "                self.save_imgs(epoch)\n",
    "\n",
    "                t2 = time.time()\n",
    "                print(f\"{t2-t1:.1f}s elapsed since, total {t2-t0:.1f}s\")\n",
    "                t1 = t2\n",
    "\n",
    "        # save model after finish\n",
    "        self.save_model(epoch)\n",
    "\n",
    "    def _visualize_fp(self, fps):\n",
    "        # adjusted for different luminance\n",
    "        channel_to_rgba = np.array(\n",
    "            [\n",
    "                [0.0, 0.0, 0.0, 1.0],  # unit mask to alpha\n",
    "                [0.0, 0.33, 0.0, 0.0],  # entrance to green L30\n",
    "                [1.0, 0.25, 0.0, 0.0],  # LDK to red L57\n",
    "                [0.0, 0.26, 1.0, 0.0],  # bedroom to blue L40\n",
    "                [0.83, 0.87, 0.0, 0.0],  # balcony to yellow L85\n",
    "                [0.0, 0.81, 0.76, 0.0],\n",
    "            ]\n",
    "        )  # bathroom to cyan L75\n",
    "\n",
    "        # make colors subtractive\n",
    "        channel_to_rgba[1:6, 0:3] -= 1\n",
    "\n",
    "        # put it on transparent white\n",
    "        fps_rgba = np.clip(\n",
    "            np.array([1.0, 1.0, 1.0, 0.0]) + (np.array(fps) @ channel_to_rgba), 0, 1\n",
    "        )\n",
    "        return fps_rgba\n",
    "\n",
    "    def _visualize_fp_onehot(self, fps):\n",
    "        # adjusted for different luminance\n",
    "        channel_to_rgba = np.array(\n",
    "            [\n",
    "                [0.0, 0.0, 0.0, 0.0],  # ignore outdoor mask\n",
    "                [0.0, 0.33, 0.0, 0.0],  # entrance to green L30\n",
    "                [1.0, 0.25, 0.0, 0.0],  # LDK to red L57\n",
    "                [0.0, 0.26, 1.0, 0.0],  # bedroom to blue L40\n",
    "                [0.83, 0.87, 0.0, 0.0],  # balcony to yellow L85\n",
    "                [0.0, 0.81, 0.76, 0.0],\n",
    "            ]\n",
    "        )  # bathroom to cyan L75\n",
    "\n",
    "        # make colors subtractive\n",
    "        channel_to_rgba[1:6, 0:3] -= 1\n",
    "\n",
    "        # put it on white\n",
    "        fps_rgba = np.clip(\n",
    "            np.array([1.0, 1.0, 1.0, 1.0]) + (np.array(fps) @ channel_to_rgba), 0, 1\n",
    "        )\n",
    "        return fps_rgba\n",
    "\n",
    "    def save_imgs(self, epoch, r=5, c=5):\n",
    "        ### create a fixed noise\n",
    "        # save the current state\n",
    "        random_state = np.random.get_state()\n",
    "        # set same noise for images\n",
    "        np.random.seed(1106)\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        # reset the state\n",
    "        np.random.set_state(random_state)\n",
    "\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        # visualize as rgba\n",
    "        gen_imgs_rgba = self._visualize_fp_onehot(gen_imgs)\n",
    "        # gen_imgs_rgba = self._visualize_fp(gen_imgs)\n",
    "\n",
    "        fig, axs = plt.subplots(r, c, figsize=(2, 2), dpi=300)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs_rgba[cnt, :, :, :])\n",
    "                axs[i, j].axis(\"off\")\n",
    "                cnt += 1\n",
    "        fig.savefig(\n",
    "            f\"{self.dir_save}/dcgan_{epoch:06}.png\", bbox_inches=\"tight\", pad_inches=0\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "    def save_model(self, end_epoch):\n",
    "        for path, model in zip(\n",
    "            [\n",
    "                f\"{self.dir_save}/dcgan_{end_epoch:06}_{name}.h5\"\n",
    "                for name in [\"gen\", \"disc\"]\n",
    "            ],\n",
    "            [self.generator, self.discriminator],\n",
    "        ):\n",
    "            with h5py.File(path, \"w\") as file:\n",
    "                weight = model.get_weights()\n",
    "                for i in range(len(weight)):\n",
    "                    file.create_dataset(\"weight\" + str(i), data=weight[i])\n",
    "\n",
    "    def load_model(self, end_epoch):\n",
    "        for path, model in zip(\n",
    "            [\n",
    "                f\"{self.dir_save}/dcgan_{end_epoch:06}_{name}.h5\"\n",
    "                for name in [\"gen\", \"disc\"]\n",
    "            ],\n",
    "            [self.generator, self.discriminator],\n",
    "        ):\n",
    "            with h5py.File(path, \"r\") as file:\n",
    "                weight = []\n",
    "                for i in range(len(file.keys())):\n",
    "                    weight.append(file[\"weight\" + str(i)][:])\n",
    "\n",
    "            model.set_weights(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 14, 14, 32)        1760      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 395,169\n",
      "Trainable params: 394,273\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 6)         3462      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 6)         0         \n",
      "=================================================================\n",
      "Total params: 859,078\n",
      "Trainable params: 858,694\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"combined\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 28, 28, 6)         859078    \n",
      "_________________________________________________________________\n",
      "model (Model)                (None, 1)                 395169    \n",
      "=================================================================\n",
      "Total params: 1,254,247\n",
      "Trainable params: 858,694\n",
      "Non-trainable params: 395,553\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dcgan = DCGAN_fp(dir_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1394: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "300 [D loss: 0.014234, acc.: 100.0%] [G loss: 5.019443] 25.1s elapsed since, total 25.1s\n",
      "310 [D loss: 0.032046, acc.: 99.2%] [G loss: 6.159709] 227.6s elapsed since, total 252.6s\n",
      "320 [D loss: 0.023849, acc.: 100.0%] [G loss: 5.359635] 228.3s elapsed since, total 480.9s\n",
      "330 [D loss: 0.040728, acc.: 99.2%] [G loss: 5.766985] 228.2s elapsed since, total 709.0s\n",
      "340 [D loss: 0.015531, acc.: 100.0%] [G loss: 4.915357] 228.4s elapsed since, total 937.4s\n",
      "350 [D loss: 0.080299, acc.: 96.9%] [G loss: 4.749314] 228.6s elapsed since, total 1166.0s\n",
      "360 [D loss: 0.057203, acc.: 98.4%] [G loss: 8.251804] 228.4s elapsed since, total 1394.4s\n",
      "370 [D loss: 0.670255, acc.: 65.6%] [G loss: 4.112588] 228.5s elapsed since, total 1622.9s\n",
      "380 [D loss: 0.418001, acc.: 82.0%] [G loss: 3.212224] 228.5s elapsed since, total 1851.4s\n",
      "390 [D loss: 0.151341, acc.: 95.3%] [G loss: 9.040207] 228.3s elapsed since, total 2079.7s\n",
      "400 [D loss: 0.059596, acc.: 97.7%] [G loss: 4.592116] 228.7s elapsed since, total 2308.4s\n",
      "410 [D loss: 0.008951, acc.: 100.0%] [G loss: 8.185869] 228.3s elapsed since, total 2536.7s\n",
      "420 [D loss: 0.010522, acc.: 100.0%] [G loss: 5.681221] 228.4s elapsed since, total 2765.1s\n",
      "430 [D loss: 0.022847, acc.: 99.2%] [G loss: 8.100058] 228.3s elapsed since, total 2993.3s\n",
      "440 [D loss: 0.017550, acc.: 100.0%] [G loss: 6.157762] 228.4s elapsed since, total 3221.7s\n",
      "450 [D loss: 0.016039, acc.: 100.0%] [G loss: 7.992780] 228.1s elapsed since, total 3449.8s\n",
      "460 [D loss: 0.003232, acc.: 100.0%] [G loss: 8.258796] 228.8s elapsed since, total 3678.6s\n",
      "470 [D loss: 0.008001, acc.: 100.0%] [G loss: 11.801312] 228.3s elapsed since, total 3906.9s\n",
      "480 [D loss: 0.112182, acc.: 95.3%] [G loss: 4.978102] 228.6s elapsed since, total 4135.5s\n",
      "490 [D loss: 0.050881, acc.: 99.2%] [G loss: 4.842236] 228.3s elapsed since, total 4363.8s\n",
      "500 [D loss: 0.004744, acc.: 100.0%] [G loss: 3.451547] 228.2s elapsed since, total 4592.0s\n",
      "510 [D loss: 0.177208, acc.: 93.8%] [G loss: 5.758066] 228.7s elapsed since, total 4820.6s\n",
      "520 [D loss: 0.020267, acc.: 99.2%] [G loss: 8.265522] 228.5s elapsed since, total 5049.1s\n",
      "530 [D loss: 0.009392, acc.: 100.0%] [G loss: 4.129930] 228.5s elapsed since, total 5277.6s\n",
      "540 [D loss: 0.006722, acc.: 100.0%] [G loss: 7.273992] 228.0s elapsed since, total 5505.6s\n",
      "550 [D loss: 0.013300, acc.: 100.0%] [G loss: 5.583888] 228.0s elapsed since, total 5733.6s\n",
      "560 [D loss: 0.013274, acc.: 100.0%] [G loss: 8.006847] 228.6s elapsed since, total 5962.2s\n",
      "570 [D loss: 0.010595, acc.: 100.0%] [G loss: 8.183929] 228.5s elapsed since, total 6190.7s\n",
      "580 [D loss: 0.015156, acc.: 99.2%] [G loss: 6.179202] 228.2s elapsed since, total 6418.9s\n",
      "590 [D loss: 0.024970, acc.: 99.2%] [G loss: 8.582663] 228.1s elapsed since, total 6647.0s\n",
      "600 [D loss: 0.006340, acc.: 100.0%] [G loss: 6.859427] 227.9s elapsed since, total 6874.9s\n",
      "610 [D loss: 0.089214, acc.: 96.1%] [G loss: 5.472298] 228.5s elapsed since, total 7103.4s\n",
      "620 [D loss: 0.049176, acc.: 98.4%] [G loss: 5.667934] 228.1s elapsed since, total 7331.5s\n",
      "630 [D loss: 0.022038, acc.: 100.0%] [G loss: 11.149355] 227.8s elapsed since, total 7559.3s\n",
      "640 [D loss: 0.017336, acc.: 100.0%] [G loss: 5.746945] 228.3s elapsed since, total 7787.6s\n",
      "650 [D loss: 0.010088, acc.: 100.0%] [G loss: 5.898097] 228.1s elapsed since, total 8015.7s\n",
      "660 [D loss: 0.025466, acc.: 99.2%] [G loss: 8.088297] 228.1s elapsed since, total 8243.8s\n",
      "670 [D loss: 0.006330, acc.: 100.0%] [G loss: 8.929094] 228.8s elapsed since, total 8472.6s\n",
      "680 [D loss: 0.027519, acc.: 100.0%] [G loss: 5.841464] 228.5s elapsed since, total 8701.1s\n",
      "690 [D loss: 0.007437, acc.: 100.0%] [G loss: 7.451663] 228.3s elapsed since, total 8929.4s\n",
      "700 [D loss: 0.034030, acc.: 98.4%] [G loss: 8.644184] 229.1s elapsed since, total 9158.5s\n",
      "710 [D loss: 0.005524, acc.: 100.0%] [G loss: 8.359676] 228.7s elapsed since, total 9387.2s\n",
      "720 [D loss: 0.015200, acc.: 100.0%] [G loss: 5.553130] 228.2s elapsed since, total 9615.4s\n",
      "730 [D loss: 0.013682, acc.: 100.0%] [G loss: 10.371580] 228.0s elapsed since, total 9843.4s\n",
      "740 [D loss: 0.004191, acc.: 100.0%] [G loss: 6.518330] 228.5s elapsed since, total 10071.9s\n",
      "750 [D loss: 0.077579, acc.: 97.7%] [G loss: 4.520609] 228.3s elapsed since, total 10300.2s\n",
      "760 [D loss: 0.288165, acc.: 84.4%] [G loss: 4.605803] 228.2s elapsed since, total 10528.4s\n",
      "770 [D loss: 0.044643, acc.: 99.2%] [G loss: 6.416888] 228.0s elapsed since, total 10756.5s\n",
      "780 [D loss: 0.016649, acc.: 100.0%] [G loss: 5.069652] 228.2s elapsed since, total 10984.7s\n",
      "790 [D loss: 0.001558, acc.: 100.0%] [G loss: 7.448100] 228.2s elapsed since, total 11212.9s\n",
      "800 [D loss: 0.002050, acc.: 100.0%] [G loss: 6.784945] 227.8s elapsed since, total 11440.6s\n",
      "810 [D loss: 0.071490, acc.: 98.4%] [G loss: 3.107015] 228.2s elapsed since, total 11668.8s\n",
      "820 [D loss: 0.004692, acc.: 100.0%] [G loss: 8.448095] 229.5s elapsed since, total 11898.4s\n",
      "830 [D loss: 0.038281, acc.: 99.2%] [G loss: 8.523355] 227.8s elapsed since, total 12126.2s\n",
      "840 [D loss: 0.001132, acc.: 100.0%] [G loss: 11.643265] 228.1s elapsed since, total 12354.2s\n",
      "850 [D loss: 0.004671, acc.: 100.0%] [G loss: 8.728497] 227.6s elapsed since, total 12581.8s\n",
      "860 [D loss: 0.673347, acc.: 67.2%] [G loss: 10.144310] 228.1s elapsed since, total 12809.9s\n",
      "870 [D loss: 0.010218, acc.: 100.0%] [G loss: 6.898005] 228.5s elapsed since, total 13038.4s\n",
      "880 [D loss: 0.069469, acc.: 97.7%] [G loss: 5.207932] 228.1s elapsed since, total 13266.5s\n",
      "890 [D loss: 0.019892, acc.: 100.0%] [G loss: 6.238173] 228.3s elapsed since, total 13494.8s\n",
      "900 [D loss: 0.039710, acc.: 99.2%] [G loss: 7.575821] 228.6s elapsed since, total 13723.4s\n",
      "910 [D loss: 0.006962, acc.: 100.0%] [G loss: 11.592937] 228.1s elapsed since, total 13951.4s\n",
      "920 [D loss: 0.013889, acc.: 99.2%] [G loss: 8.766426] 228.7s elapsed since, total 14180.1s\n",
      "930 [D loss: 0.019533, acc.: 100.0%] [G loss: 6.203604] 229.1s elapsed since, total 14409.2s\n",
      "940 [D loss: 0.002005, acc.: 100.0%] [G loss: 6.417036] 228.6s elapsed since, total 14637.8s\n",
      "950 [D loss: 0.004385, acc.: 100.0%] [G loss: 12.871910] 228.6s elapsed since, total 14866.4s\n",
      "960 [D loss: 0.024415, acc.: 99.2%] [G loss: 10.148670] 228.6s elapsed since, total 15095.0s\n",
      "970 [D loss: 0.491788, acc.: 76.6%] [G loss: 10.230358] 229.4s elapsed since, total 15324.4s\n",
      "980 [D loss: 0.035609, acc.: 98.4%] [G loss: 8.924668] 228.3s elapsed since, total 15552.7s\n",
      "990 [D loss: 0.029088, acc.: 99.2%] [G loss: 5.751415] 228.4s elapsed since, total 15781.1s\n",
      "1000 [D loss: 0.031573, acc.: 99.2%] [G loss: 7.624339] 228.4s elapsed since, total 16009.5s\n",
      "1010 [D loss: 0.032669, acc.: 99.2%] [G loss: 6.527164] 228.2s elapsed since, total 16237.7s\n",
      "1020 [D loss: 0.140292, acc.: 94.5%] [G loss: 5.538204] 227.8s elapsed since, total 16465.5s\n",
      "1030 [D loss: 0.027186, acc.: 99.2%] [G loss: 5.080138] 228.2s elapsed since, total 16693.7s\n",
      "1040 [D loss: 0.041109, acc.: 99.2%] [G loss: 11.460507] 228.0s elapsed since, total 16921.7s\n",
      "1050 [D loss: 0.028544, acc.: 99.2%] [G loss: 5.323227] 228.1s elapsed since, total 17149.8s\n",
      "1060 [D loss: 0.012055, acc.: 99.2%] [G loss: 7.375958] 228.7s elapsed since, total 17378.5s\n",
      "1070 [D loss: 0.008544, acc.: 100.0%] [G loss: 8.047606] 228.5s elapsed since, total 17607.1s\n",
      "1080 [D loss: 0.002934, acc.: 100.0%] [G loss: 11.406143] 228.1s elapsed since, total 17835.2s\n",
      "1090 [D loss: 0.035891, acc.: 99.2%] [G loss: 6.350327] 228.3s elapsed since, total 18063.5s\n",
      "1100 [D loss: 0.020235, acc.: 100.0%] [G loss: 7.072034] 228.0s elapsed since, total 18291.5s\n",
      "1110 [D loss: 0.396434, acc.: 78.1%] [G loss: 3.057571] 228.2s elapsed since, total 18519.7s\n",
      "1120 [D loss: 0.025074, acc.: 99.2%] [G loss: 8.014429] 228.2s elapsed since, total 18747.9s\n",
      "1130 [D loss: 0.004475, acc.: 100.0%] [G loss: 2.182487] 228.1s elapsed since, total 18976.0s\n",
      "1140 [D loss: 0.003493, acc.: 100.0%] [G loss: 12.037304] 228.0s elapsed since, total 19204.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1150 [D loss: 0.006007, acc.: 100.0%] [G loss: 7.913059] 229.3s elapsed since, total 19433.4s\n",
      "1160 [D loss: 0.041196, acc.: 98.4%] [G loss: 7.040613] 228.4s elapsed since, total 19661.8s\n",
      "1170 [D loss: 0.045575, acc.: 99.2%] [G loss: 8.322030] 228.4s elapsed since, total 19890.1s\n",
      "1180 [D loss: 0.020733, acc.: 100.0%] [G loss: 5.542104] 227.3s elapsed since, total 20117.5s\n",
      "1190 [D loss: 0.006270, acc.: 100.0%] [G loss: 10.060768] 227.7s elapsed since, total 20345.1s\n",
      "1200 [D loss: 0.002221, acc.: 100.0%] [G loss: 6.351820] 227.8s elapsed since, total 20572.9s\n",
      "1210 [D loss: 0.002263, acc.: 100.0%] [G loss: 10.253221] 227.9s elapsed since, total 20800.8s\n",
      "1220 [D loss: 0.007871, acc.: 100.0%] [G loss: 10.900143] 228.4s elapsed since, total 21029.2s\n",
      "1230 [D loss: 0.001089, acc.: 100.0%] [G loss: 10.958556] 228.3s elapsed since, total 21257.5s\n",
      "1240 [D loss: 0.000332, acc.: 100.0%] [G loss: 10.216215] 227.8s elapsed since, total 21485.4s\n",
      "1250 [D loss: 0.010889, acc.: 100.0%] [G loss: 6.453494] 227.7s elapsed since, total 21713.1s\n",
      "1260 [D loss: 0.009351, acc.: 100.0%] [G loss: 8.492926] 227.8s elapsed since, total 21940.9s\n",
      "1270 [D loss: 0.018617, acc.: 100.0%] [G loss: 9.470191] 227.2s elapsed since, total 22168.1s\n",
      "1280 [D loss: 0.039758, acc.: 100.0%] [G loss: 4.280677] 227.5s elapsed since, total 22395.6s\n",
      "1290 [D loss: 0.002768, acc.: 100.0%] [G loss: 7.848823] 227.8s elapsed since, total 22623.4s\n",
      "1299 [D loss: 0.006240, acc.: 100.0%] [G loss: 6.897532] 204.8s elapsed since, total 22828.2s\n"
     ]
    }
   ],
   "source": [
    "dcgan.train(\n",
    "    path_full_tfrecord,\n",
    "    epochs=1000,\n",
    "    initial_epoch=300,\n",
    "    batch_size=128,\n",
    "    save_interval=10,\n",
    ")\n",
    "\n",
    "# 128*1000 -> less than 202s (now skip training on overpowering one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
