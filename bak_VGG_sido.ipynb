{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.9 (default, Nov  7 2019, 10:44:02) \n",
      "[GCC 8.3.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/eriklindernoren/Keras-GAN/blob/master/infogan/infogan.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    Reshape,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    "    Activation,\n",
    "    ZeroPadding2D,\n",
    "    LeakyReLU,\n",
    "    UpSampling2D,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Concatenate,\n",
    "    GaussianNoise,\n",
    "    GaussianDropout,\n",
    "    Lambda,\n",
    ")\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import pathlib\n",
    "\n",
    "import time\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  1.15.2\n",
      "Keras version:  2.2.4-tf\n",
      "Is eager execution enabled:  True\n",
      "Is there a GPU available:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow version: \", tf.VERSION)  # 1.13.1\n",
    "print(\"Keras version: \", tf.keras.__version__)  # 2.2.4-tf\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "print(\"Is eager execution enabled: \", tf.executing_eagerly())\n",
    "print(\"Is there a GPU available: \", tf.test.is_gpu_available())\n",
    "\n",
    "# from tensorflow.python.client import device_lib\n",
    "# print('List of GPUs:\\n',\n",
    "#       [x for x in device_lib.list_local_devices()\n",
    "#        if x.device_type == \"GPU\" or x.device_type == \"SYCL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"vgg_sido\"\n",
    "\n",
    "path_train_tfrecord = \"/data/fp85_train.tfrecord\"\n",
    "path_test_tfrecord = \"/data/fp85_test.tfrecord\"\n",
    "\n",
    "predict_only = False\n",
    "predict_test_only = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 12736, 'test': 3309}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_examples = {\n",
    "    key: sum(1 for _ in tf.data.TFRecordDataset(path, compression_type=\"GZIP\"))\n",
    "    for key, path in {\"train\": path_train_tfrecord, \"test\": path_test_tfrecord}.items()\n",
    "}\n",
    "n_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = filename + \".h5\"\n",
    "\n",
    "dir_model = os.path.dirname(path_model)\n",
    "pathlib.Path(dir_model).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((?, 28, 28, 6), (?, 9)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://medium.com/@moritzkrger/speeding-up-keras-with-tfrecord-datasets-5464f9836c36\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "BUFFER_SIZE = 1024\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "IMAGE_DIMS = (28, 28, 6)\n",
    "LABEL_DIM = 9\n",
    "\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    # Create a description of the features.\n",
    "    feature_description = {\n",
    "        \"floorplan\": tf.io.FixedLenFeature(\n",
    "            [28, 28, 6], tf.float32, default_value=tf.zeros([28, 28, 6], tf.float32)\n",
    "        ),\n",
    "        \"plan_id\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "        \"norm_year\": tf.io.FixedLenFeature([], tf.float32, default_value=-1.0),\n",
    "        \"sido\": tf.io.FixedLenFeature([], tf.int64, default_value=-1),\n",
    "        \"norm_area\": tf.io.FixedLenFeature([], tf.float32, default_value=0.0),\n",
    "        \"num_rooms\": tf.io.FixedLenFeature([], tf.int64, default_value=-1),\n",
    "        \"num_baths\": tf.io.FixedLenFeature([], tf.int64, default_value=-1),\n",
    "        \"brands\": tf.io.FixedLenFeature(\n",
    "            [12], tf.int64, default_value=tf.zeros([12], tf.int64)\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    # Parse the input tf.Example proto using the dictionary above.\n",
    "    parsed_example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "    #     return (parsed_example[\"floorplan\"],)\n",
    "    return (parsed_example[\"floorplan\"], parsed_example[\"sido\"])\n",
    "\n",
    "\n",
    "def _onehot_fp(fp, *rest):\n",
    "    \"\"\"\n",
    "    Replace unit layer with outdoor layer and restrict function space layers indoor\n",
    "    \"\"\"\n",
    "    fp_func = fp[:, :, 1:6] * tf.reshape(fp[:, :, 0], (28, 28, 1))\n",
    "    fp_out = tf.reshape(1 - fp[:, :, 0], (28, 28, 1))\n",
    "    return (tf.concat([fp_out, fp_func], axis=2), *rest)\n",
    "\n",
    "\n",
    "def _rescale_fp(fp, *rest):\n",
    "    \"\"\"\n",
    "    Rescale from [0, 1] to [-1, 1]\n",
    "    \"\"\"\n",
    "    return (fp * 2 - 1, *rest)\n",
    "\n",
    "\n",
    "def _onehot_sido(fp, sido, *rest):\n",
    "    \"\"\"\n",
    "    Make sido label into one-hot vector\n",
    "    \"\"\"\n",
    "    return (fp, tf.one_hot(sido, LABEL_DIM), *rest)\n",
    "\n",
    "\n",
    "def create_dataset(filepath):\n",
    "\n",
    "    # This works with arrays as well\n",
    "    dataset = tf.data.TFRecordDataset(filepath, compression_type=\"GZIP\")\n",
    "\n",
    "    # Maps the parser on every filepath in the array. You can set the number of parallel loaders here\n",
    "    dataset = dataset.map(_parse_function, num_parallel_calls=4)\n",
    "\n",
    "    # make the floorplan one-hot-ish\n",
    "    dataset = dataset.map(_onehot_fp, num_parallel_calls=4)\n",
    "\n",
    "    # rescale to [-1, 1]\n",
    "    dataset = dataset.map(_rescale_fp, num_parallel_calls=4)\n",
    "\n",
    "    # make sido one-hot\n",
    "    dataset = dataset.map(_onehot_sido, num_parallel_calls=4)\n",
    "\n",
    "    # This dataset will go on forever\n",
    "    dataset = dataset.repeat()\n",
    "\n",
    "    # Set the number of datapoints you want to load and shuffle\n",
    "    dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "\n",
    "    # Set the batchsize\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_dataset = create_dataset(path_train_tfrecord)\n",
    "test_dataset = create_dataset(path_test_tfrecord)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SmallerVGGNet, with noise layer added\n",
    "\n",
    "Source:\n",
    "https://www.pyimagesearch.com/2018/05/07/multi-label-classification-with-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallerVGGNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        # initialize the model along with the input shape to be\n",
    "        # \"channels last\" and the channels dimension itself\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "\n",
    "        # if we are using \"channels first\", update the input shape\n",
    "        # and channels dimension\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "            chanDim = 1\n",
    "\n",
    "        # add black & white noise to input data\n",
    "        if chanDim == -1:\n",
    "            noiseShape = (height, width, 1)\n",
    "        else:\n",
    "            noiseShape = (1, height, width)\n",
    "\n",
    "        model.add(Dropout(0.2, noise_shape=noiseShape, input_shape=inputShape))  # gray\n",
    "        model.add(GaussianNoise(0.1))  # 0-centered noise\n",
    "\n",
    "        # CONV => RELU => POOL\n",
    "        model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        # first (and only) set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        # use a *softmax* activation for single-label classification\n",
    "        # and *sigmoid* activation for multi-label classification\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "#         model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "        # return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout (Dropout)            (None, 28, 28, 6)         0         \n",
      "_________________________________________________________________\n",
      "gaussian_noise (GaussianNois (None, 28, 28, 6)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 6)         24        \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        1760      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 9, 9, 64)          18496     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 9, 9, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 4617      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 549,633\n",
      "Trainable params: 547,765\n",
      "Non-trainable params: 1,868\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = SmallerVGGNet.build(\n",
    "    width=IMAGE_DIMS[1], height=IMAGE_DIMS[0], depth=IMAGE_DIMS[2], classes=LABEL_DIM\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"RMSprop\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1592 steps, validate for 413 steps\n",
      "Epoch 1/1000\n",
      "1592/1592 [==============================] - 12s 8ms/step - loss: 0.0905 - val_loss: 0.1382\n",
      "Epoch 2/1000\n",
      "1592/1592 [==============================] - 10s 6ms/step - loss: 0.0792 - val_loss: 0.1390\n",
      "Epoch 3/1000\n",
      "1592/1592 [==============================] - 10s 6ms/step - loss: 0.0728 - val_loss: 0.1577\n",
      "Epoch 4/1000\n",
      "1592/1592 [==============================] - 10s 6ms/step - loss: 0.0685 - val_loss: 0.1972\n",
      "Epoch 5/1000\n",
      "1592/1592 [==============================] - 10s 6ms/step - loss: 0.0608 - val_loss: 0.2218\n",
      "Epoch 6/1000\n",
      "1592/1592 [==============================] - 10s 6ms/step - loss: 0.0574 - val_loss: 0.2218\n",
      "Epoch 7/1000\n",
      "1592/1592 [==============================] - 10s 6ms/step - loss: 0.0581 - val_loss: 0.2218\n",
      "Epoch 8/1000\n",
      "1592/1592 [==============================] - 10s 6ms/step - loss: 0.0577 - val_loss: 0.1577\n",
      "Epoch 9/1000\n",
      "1592/1592 [==============================] - 10s 6ms/step - loss: 0.0585 - val_loss: 0.2218\n",
      "Epoch 10/1000\n",
      "1592/1592 [==============================] - 10s 6ms/step - loss: 0.0567 - val_loss: 0.2185\n",
      "Epoch 11/1000\n",
      "1592/1592 [==============================] - 10s 6ms/step - loss: 0.0583 - val_loss: 0.1924\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "if not predict_only:\n",
    "    monitor = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=10, verbose=1\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=1000,\n",
    "        steps_per_epoch=n_examples[\"train\"] // BATCH_SIZE,\n",
    "        validation_data=test_dataset,\n",
    "        validation_steps=n_examples[\"test\"] // BATCH_SIZE,\n",
    "        callbacks=[monitor],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not predict_only:\n",
    "    # save the loss\n",
    "    H = history\n",
    "    N = len(H.history[\"loss\"])\n",
    "\n",
    "    df_history = pd.DataFrame(\n",
    "        {\n",
    "            \"epoch\": np.arange(1, N + 1),\n",
    "            \"train_loss\": H.history[\"loss\"],\n",
    "            \"val_loss\": H.history[\"val_loss\"],\n",
    "        }\n",
    "    )\n",
    "    df_history = df_history.set_index(\"epoch\")\n",
    "    df_history.to_csv(filename + \"_loss.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss\n",
    "\n",
    "df_history = pd.read_csv(filename + \"_loss.csv\", index_col=\"epoch\")\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "fig = plt.figure(figsize=(11, 5), dpi=300)\n",
    "plt.plot(df_history.index, df_history[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(df_history.index, df_history[\"val_loss\"], label=\"val_loss\")\n",
    "\n",
    "# plt.ylim(top=0.05)\n",
    "\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.savefig(\n",
    "    filename + \".pdf\", bbox_inches=\"tight\", pad_inches=0,\n",
    ")\n",
    "plt.savefig(\n",
    "    filename + \".png\", bbox_inches=\"tight\", pad_inches=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not predict_only:\n",
    "    print(\"loss:    \", H.history[\"loss\"][-1])\n",
    "    print(\"val_loss:\", H.history[\"val_loss\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not predict_only:\n",
    "    with h5py.File(path_model, \"w\") as file:\n",
    "        weight = model.get_weights()\n",
    "        for i in range(len(weight)):\n",
    "            file.create_dataset(\"weight\" + str(i), data=weight[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -al {path_model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(path_model, \"r\") as file:\n",
    "    weight = []\n",
    "    for i in range(len(file.keys())):\n",
    "        weight.append(file[\"weight\" + str(i)][:])\n",
    "\n",
    "model.set_weights(weight)\n",
    "# weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_predict_function(example_proto):\n",
    "    # Create a description of the features.\n",
    "    feature_description = {\n",
    "        \"floorplan\": tf.io.FixedLenFeature(\n",
    "            [28, 28, 6], tf.float32, default_value=tf.zeros([28, 28, 6], tf.float32)\n",
    "        ),\n",
    "        \"plan_id\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "        \"norm_year\": tf.io.FixedLenFeature([], tf.float32, default_value=-1.0),\n",
    "        \"sido\": tf.io.FixedLenFeature([], tf.int64, default_value=-1),\n",
    "        \"norm_area\": tf.io.FixedLenFeature([], tf.float32, default_value=0.0),\n",
    "        \"num_rooms\": tf.io.FixedLenFeature([], tf.int64, default_value=-1),\n",
    "        \"num_baths\": tf.io.FixedLenFeature([], tf.int64, default_value=-1),\n",
    "        \"brands\": tf.io.FixedLenFeature(\n",
    "            [12], tf.int64, default_value=tf.zeros([12], tf.int64)\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    # Parse the input tf.Example proto using the dictionary above.\n",
    "    parsed_example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "    #     return (parsed_example[\"floorplan\"],)\n",
    "    return (\n",
    "        parsed_example[\"floorplan\"],\n",
    "        parsed_example[\"sido\"],\n",
    "        parsed_example[\"plan_id\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def create_predict_dataset(filepath):\n",
    "\n",
    "    # This works with arrays as well\n",
    "    dataset = tf.data.TFRecordDataset(filepath, compression_type=\"GZIP\")\n",
    "\n",
    "    # Maps the parser on every filepath in the array. You can set the number of parallel loaders here\n",
    "    dataset = dataset.map(_parse_predict_function, num_parallel_calls=4)\n",
    "\n",
    "    # make the floorplan one-hot-ish\n",
    "    dataset = dataset.map(_onehot_fp, num_parallel_calls=4)\n",
    "\n",
    "    # rescale to [-1, 1]\n",
    "    #     dataset = dataset.map(_rescale_fp, num_parallel_calls=4)\n",
    "\n",
    "    # make sido one-hot\n",
    "    dataset = dataset.map(_onehot_sido, num_parallel_calls=4)\n",
    "\n",
    "    # Set the batchsize\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if predict_test_only:\n",
    "    paths_predict_tfrecord = [path_test_tfrecord]\n",
    "else:\n",
    "    paths_predict_tfrecord = [path_train_tfrecord, path_test_tfrecord]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dataset = create_predict_dataset(paths_predict_tfrecord)\n",
    "n_examples[\"predict\"] = sum(\n",
    "    1 for _ in tf.data.TFRecordDataset(paths_predict_tfrecord, compression_type=\"GZIP\")\n",
    ")\n",
    "\n",
    "predictions = model.predict(\n",
    "    predict_dataset, steps=n_examples[\"predict\"] // BATCH_SIZE + 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.printoptions(precision=1, suppress=True):\n",
    "    print(predictions[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dataset = create_predict_dataset(paths_predict_tfrecord)\n",
    "iter = predict_dataset.make_one_shot_iterator()\n",
    "\n",
    "ids = []\n",
    "true_label = []\n",
    "\n",
    "for batch in iter:\n",
    "    true_label.extend(batch[1].numpy())\n",
    "    ids.extend(batch[-1].numpy())\n",
    "\n",
    "ids = [x.decode() for x in ids]\n",
    "true_label = np.asarray(true_label)\n",
    "ids[:10], true_label[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    zip(ids, true_label.argmax(axis=-1), predictions.argmax(axis=-1)),\n",
    "    columns=[\"ID\", \"true\", \"prediction\"],\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby([\"true\", \"prediction\"]).count().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_year = df[\"true\"].corr(df[\"prediction\"])\n",
    "r2_text = format(corr_year ** 2, \".3f\")\n",
    "r2_text = \"$r^2 = \" + r2_text + \"$\"\n",
    "\n",
    "if predict_test_only:\n",
    "    r2_text += \"\\n(Test dataset only)\"\n",
    "\n",
    "r2_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 5), dpi=300)\n",
    "ax = fig.gca()\n",
    "\n",
    "ax = df.plot.hexbin(\n",
    "    x=\"true\",\n",
    "    y=\"prediction\",\n",
    "    extent=(-0.03, 1.01, -0.03, 1.01),\n",
    "    xlim=(0, 1),\n",
    "    ylim=(0, 1),\n",
    "    sharex=False,\n",
    "    gridsize=26,\n",
    "    bins=\"log\",\n",
    "    mincnt=10,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_facecolor(\"w\")\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.text(0.02, 0.98, r2_text, verticalalignment=\"top\")\n",
    "\n",
    "if predict_test_only:\n",
    "    dataset_tag = \"_testonly\"\n",
    "else:\n",
    "    dataset_tag = \"\"\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "fig.savefig(\n",
    "    \"/data/\" + filename + \"_prediction\" + dataset_tag + \".pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    "    pad_inches=0,\n",
    ")\n",
    "fig.savefig(\n",
    "    \"/data/\" + filename + \"_prediction\" + dataset_tag + \".png\",\n",
    "    bbox_inches=\"tight\",\n",
    "    pad_inches=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
